"""
Sistema de cach√© de m√©tricas en SQLite para actualizaci√≥n as√≠ncrona de cards
sin bloquear el front-end
"""
import sqlite3
import threading
import time
import logging
from datetime import datetime
from typing import Dict, Any, Optional
from pathlib import Path

logger = logging.getLogger(__name__)


class MetricsCacheManager:
    """
    Gestor de cach√© de m√©tricas en SQLite para evitar congelamientos en el front-end.
    
    Estrategia:
    1. Worker background sincroniza m√©tricas desde MySQL a SQLite cada N segundos
    2. UI lee m√©tricas instant√°neamente desde SQLite (sin bloqueos)
    3. Actualizaciones inmediatas al escanear se reflejan primero en SQLite
    """
    
    def __init__(self, sqlite_path: Path):
        self.sqlite_path = sqlite_path
        self._lock = threading.RLock()
        self._worker_thread = None
        self._stop_worker = threading.Event()
        self._update_interval = 3  # Actualizar cada 3 segundos
        
        # L√≠nea activa actual (solo sincronizar esta)
        self._active_line: Optional[str] = None
        
        # Inicializar tabla de cach√©
        self._init_cache_table()
        
        logger.info("‚úÖ MetricsCacheManager inicializado")
    
    def set_active_line(self, linea: str):
        """Establece la l√≠nea activa para sincronizaci√≥n"""
        with self._lock:
            if self._active_line != linea:
                self._active_line = linea
                logger.info(f"üéØ L√≠nea activa cambiada a: {linea}")
    
    def get_active_line(self) -> Optional[str]:
        """Obtiene la l√≠nea activa actual"""
        with self._lock:
            return self._active_line
    
    def _init_cache_table(self):
        """Crea tabla de cach√© de m√©tricas si no existe"""
        try:
            with sqlite3.connect(self.sqlite_path, timeout=10) as conn:
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS metrics_cache (
                        linea TEXT NOT NULL,
                        fecha TEXT NOT NULL,
                        plan_total INTEGER DEFAULT 0,
                        plan_acumulado INTEGER DEFAULT 0,
                        produccion_real INTEGER DEFAULT 0,
                        eficiencia REAL DEFAULT 0.0,
                        uph REAL DEFAULT 0.0,
                        upph REAL DEFAULT 0.0,
                        num_personas INTEGER DEFAULT 0,
                        minutos_efectivos_total INTEGER DEFAULT 0,
                        minutos_efectivos_transcurridos INTEGER DEFAULT 0,
                        updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                        PRIMARY KEY (linea, fecha)
                    )
                """)
                
                # √çndice para consultas r√°pidas
                conn.execute("""
                    CREATE INDEX IF NOT EXISTS idx_metrics_linea_fecha 
                    ON metrics_cache(linea, fecha)
                """)
                
                conn.commit()
                logger.debug("‚úÖ Tabla metrics_cache inicializada")
        except Exception as e:
            logger.error(f"‚ùå Error inicializando tabla metrics_cache: {e}")
    
    def update_metrics_instant(self, linea: str, fecha: str, metrics: Dict[str, Any]):
        """
        Actualizaci√≥n instant√°nea de m√©tricas (llamado despu√©s de cada escaneo)
        Esta actualizaci√≥n es local y no bloquea
        """
        try:
            with self._lock:
                with sqlite3.connect(self.sqlite_path, timeout=10) as conn:
                    conn.execute("""
                        INSERT OR REPLACE INTO metrics_cache (
                            linea, fecha, plan_total, plan_acumulado, 
                            produccion_real, eficiencia, uph, upph,
                            num_personas, minutos_efectivos_total,
                            minutos_efectivos_transcurridos, updated_at
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        linea, fecha,
                        metrics.get('plan_total', 0),
                        metrics.get('plan_acumulado', 0),
                        metrics.get('produccion_real', 0),
                        metrics.get('eficiencia', 0.0),
                        metrics.get('uph', 0.0),
                        metrics.get('upph', 0.0),
                        metrics.get('num_personas', 0),
                        metrics.get('minutos_efectivos_total', 0),
                        metrics.get('minutos_efectivos_transcurridos', 0),
                        datetime.now().isoformat()
                    ))
                    conn.commit()
                    
            logger.debug(f"üìä M√©tricas actualizadas en cach√© para {linea} - {fecha}")
        except Exception as e:
            logger.error(f"‚ùå Error actualizando m√©tricas en cach√©: {e}")
    
    def get_metrics_from_cache(self, linea: str, fecha: str) -> Optional[Dict[str, Any]]:
        """
        Obtiene m√©tricas desde cach√© (ultra-r√°pido, sin bloqueos)
        """
        try:
            with sqlite3.connect(self.sqlite_path, timeout=5) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT * FROM metrics_cache 
                    WHERE linea = ? AND fecha = ?
                """, (linea, fecha))
                
                row = cursor.fetchone()
                
                if row:
                    metrics = {
                        'plan_total': row['plan_total'],
                        'plan_acumulado': row['plan_acumulado'],
                        'produccion_real': row['produccion_real'],
                        'eficiencia': row['eficiencia'],
                        'uph': row['uph'],
                        'upph': row['upph'],
                        'num_personas': row['num_personas'],
                        'minutos_efectivos_total': row['minutos_efectivos_total'],
                        'minutos_efectivos_transcurridos': row['minutos_efectivos_transcurridos'],
                        'updated_at': row['updated_at']
                    }
                    
                    logger.debug(f"‚úÖ M√©tricas le√≠das desde cach√©: {linea} - Eficiencia: {metrics['eficiencia']:.1f}%")
                    return metrics
                else:
                    logger.debug(f"‚ö†Ô∏è No hay m√©tricas en cach√© para {linea} - {fecha}")
                    return None
                    
        except Exception as e:
            logger.error(f"‚ùå Error leyendo m√©tricas desde cach√©: {e}")
            return None
    
    def calculate_and_update_metrics(self, linea: str, fecha: str, plan_rows: list = None, num_personas: int = None):
        """
        Calcula m√©tricas DIRECTAMENTE desde SQLite (plan_local)
        ‚úÖ Ultra-r√°pido: Lee producci√≥n real directamente de la BD
        ‚úÖ Sin c√°lculos complejos: Suma simple de plan_count y produced_count
        
        Args:
            linea: L√≠nea de producci√≥n
            fecha: Fecha en formato ISO
            plan_rows: Filas del plan (opcional)
            num_personas: N√∫mero de personas (opcional, si no se provee usa valor por defecto)
        """
        try:
            # ‚úÖ Leer datos directamente de SQLite
            with sqlite3.connect(self.sqlite_path, timeout=5) as conn:
                cursor = conn.cursor()
                
                # Obtener plan total y producci√≥n total de la l√≠nea
                cursor.execute("""
                    SELECT 
                        SUM(plan_count) as plan_total,
                        SUM(produced_count) as produccion_total
                    FROM plan_local
                    WHERE line = ?
                """, (linea,))
                
                result = cursor.fetchone()
                plan_total_linea = result[0] or 0
                produccion_acumulada = result[1] or 0
                
                logger.debug(f"üìä [CACHE] SQLite: {linea} - Plan={plan_total_linea}, Prod={produccion_acumulada}")
            
            # Calcular plan acumulado (por ahora igual al plan total)
            # TODO: Implementar c√°lculo con minutos efectivos si es necesario
            plan_acumulado = plan_total_linea
            
            # Calcular eficiencia
            if plan_acumulado > 0:
                eficiencia = (produccion_acumulada / plan_acumulado) * 100
            else:
                eficiencia = 0.0
            
            # Calcular UPH (√∫ltima hora) - AHORA CUENTA PARES COMPLETOS
            uph = self._calculate_uph_from_db(linea, fecha)
            
            # Obtener n√∫mero de personas
            if num_personas is None:
                # Intentar obtener desde configuraci√≥n como fallback
                from ..config import settings
                num_personas = getattr(settings, 'NUM_PERSONAS_LINEA', 6)
            
            # Calcular UPPH
            upph = (uph / num_personas) if num_personas > 0 else 0.0
            
            # Crear diccionario de m√©tricas
            metrics = {
                'plan_total': plan_total_linea,
                'plan_acumulado': plan_acumulado,
                'produccion_real': produccion_acumulada,
                'eficiencia': eficiencia,
                'uph': uph,
                'upph': upph,
                'num_personas': num_personas,
                'minutos_efectivos_total': 450,  # Placeholder
                'minutos_efectivos_transcurridos': 0  # Placeholder
            }
            
            # Actualizar cach√©
            self.update_metrics_instant(linea, fecha, metrics)
            
            logger.debug(f"‚úÖ [CACHE] M√©tricas actualizadas: {linea} - Plan={plan_total_linea}, Prod={produccion_acumulada}, Efic={eficiencia:.1f}%, UPH={uph}, UPPH={upph:.2f}")
            
        except Exception as e:
            logger.error(f"‚ùå Error calculando m√©tricas desde SQLite: {e}", exc_info=True)
    
    def _calculate_uph_from_db(self, linea: str, fecha: str) -> float:
        """
        Calcula UPH como velocidad proyectada (piezas por hora basado en tiempo transcurrido)
        UPH = (total_piezas_completas / segundos_transcurridos) * 3600
        Nunca retorna 0 si hay al menos 1 scan completo
        """
        try:
            with sqlite3.connect(self.sqlite_path, timeout=5) as conn:
                cursor = conn.cursor()
                
                # Obtener el primer y √∫ltimo scan del turno actual, m√°s el total de piezas
                cursor.execute("""
                    SELECT 
                        COUNT(*)/2 as total_piezas,
                        MIN(ts) as primer_scan,
                        MAX(ts) as ultimo_scan
                    FROM scans_local
                    WHERE linea = ?
                    AND fecha = ?
                    AND is_complete = 1
                """, (linea, fecha))
                
                result = cursor.fetchone()
                
                if not result or not result[0] or result[0] == 0:
                    return 0.0
                
                total_piezas = float(result[0])
                primer_scan = result[1]
                ultimo_scan = result[2]
                
                if not primer_scan or not ultimo_scan:
                    return 0.0
                
                # Calcular segundos transcurridos desde el primer scan
                cursor.execute("""
                    SELECT (julianday(?) - julianday(?)) * 86400 as segundos
                """, (ultimo_scan, primer_scan))
                
                segundos_result = cursor.fetchone()
                segundos_transcurridos = float(segundos_result[0]) if segundos_result else 0.0
                
                # Usar m√≠nimo de 60 segundos (1 minuto) para evitar proyecciones irreales
                # Ejemplo: 1 pieza en 5 segundos NO debe proyectar 720 UPH
                SEGUNDOS_MINIMOS = 60.0
                if segundos_transcurridos < SEGUNDOS_MINIMOS:
                    segundos_transcurridos = SEGUNDOS_MINIMOS
                
                # UPH = (piezas / segundos) * 3600 segundos/hora
                uph_proyectado = (total_piezas / segundos_transcurridos) * 3600.0
                
                logger.debug(f"üìä UPH calculado: {total_piezas} piezas en {segundos_transcurridos:.1f}s = {uph_proyectado:.1f} UPH")
                
                return uph_proyectado
                
        except Exception as e:
            logger.error(f"‚ùå Error calculando UPH: {e}")
            return 0.0
    
    def start_background_sync(self, dual_db_instance):
        """
        Inicia worker en background que sincroniza m√©tricas peri√≥dicamente
        """
        if self._worker_thread and self._worker_thread.is_alive():
            logger.warning("‚ö†Ô∏è Worker de m√©tricas ya est√° corriendo")
            return
        
        self._stop_worker.clear()
        self._worker_thread = threading.Thread(
            target=self._metrics_sync_worker,
            args=(dual_db_instance,),
            daemon=True,
            name="MetricsSyncWorker"
        )
        self._worker_thread.start()
        logger.info("üöÄ Worker de sincronizaci√≥n de m√©tricas iniciado")
    
    def _metrics_sync_worker(self, dual_db_instance):
        """Worker que actualiza m√©tricas en background"""
        logger.info("üîÑ Metrics sync worker iniciado")
        
        while not self._stop_worker.is_set():
            try:
                # Obtener l√≠nea activa
                linea_activa = self.get_active_line()
                
                # Solo sincronizar si hay una l√≠nea activa
                if not linea_activa:
                    logger.debug("‚è∏Ô∏è Sin l√≠nea activa, esperando...")
                    time.sleep(self._update_interval)
                    continue
                
                # Obtener fecha actual
                from datetime import date
                fecha_hoy = date.today().isoformat()
                
                # Sincronizar SOLO la l√≠nea activa
                try:
                    # Obtener plan_rows desde dual_db
                    plan_rows = dual_db_instance.get_plan_for_line_local(linea_activa)
                    
                    if plan_rows:
                        # Calcular y actualizar m√©tricas
                        self.calculate_and_update_metrics(linea_activa, fecha_hoy, plan_rows)
                        logger.debug(f"‚úÖ M√©tricas sincronizadas para {linea_activa}")
                    else:
                        logger.debug(f"‚ö†Ô∏è Sin plan para {linea_activa}")
                    
                except Exception as e:
                    logger.error(f"‚ùå Error sincronizando m√©tricas para {linea_activa}: {e}")
                
                # Esperar antes del pr√≥ximo ciclo
                time.sleep(self._update_interval)
                
            except Exception as e:
                logger.error(f"‚ùå Error en metrics sync worker: {e}")
                time.sleep(5)  # Esperar m√°s tiempo si hay error
        
        logger.info("üõë Metrics sync worker detenido")
    
    def stop_background_sync(self):
        """Detiene el worker de sincronizaci√≥n"""
        self._stop_worker.set()
        if self._worker_thread:
            self._worker_thread.join(timeout=5)
        logger.info("üõë Worker de m√©tricas detenido")
    
    def cleanup_old_cache(self, days_to_keep: int = 7):
        """Limpia cach√© de m√©tricas antiguas"""
        try:
            with sqlite3.connect(self.sqlite_path, timeout=10) as conn:
                conn.execute("""
                    DELETE FROM metrics_cache 
                    WHERE datetime(updated_at) < datetime('now', '-' || ? || ' days')
                """, (days_to_keep,))
                conn.commit()
                logger.info(f"üßπ Cach√© de m√©tricas limpiado (>{days_to_keep} d√≠as)")
        except Exception as e:
            logger.error(f"‚ùå Error limpiando cach√© de m√©tricas: {e}")


# Instancia global (se inicializa desde dual_db.py)
metrics_cache: Optional[MetricsCacheManager] = None


def init_metrics_cache(sqlite_path: Path) -> MetricsCacheManager:
    """Inicializa el gestor de cach√© de m√©tricas"""
    global metrics_cache
    metrics_cache = MetricsCacheManager(sqlite_path)
    return metrics_cache


def get_metrics_cache() -> Optional[MetricsCacheManager]:
    """Obtiene la instancia global del cach√© de m√©tricas"""
    return metrics_cache
